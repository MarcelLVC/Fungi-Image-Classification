{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db363bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4098fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Hitung GLCM (jarak 1 pixel, sudut 0, 45, 90, 135 derajat)\n",
    "    # levels=256 karena citra 8-bit standard\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    features = []\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    \n",
    "    for prop in props:\n",
    "        # Karena kita punya 4 sudut, kita ambil rata-ratanya agar fitur invarian terhadap rotasi\n",
    "        val = graycoprops(glcm, prop).mean()\n",
    "        features.append(val)\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0365c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    \n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Hitung histogram dari hasil LBP\n",
    "    # bin = n_points + 2\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    \n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9815fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hsv_features(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # bins=8 per channel agar fitur tidak terlalu banyak (total 24 fitur)\n",
    "    bins = 8\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [bins], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [bins], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [bins], [0, 256])\n",
    "\n",
    "    cv2.normalize(hist_h, hist_h)\n",
    "    cv2.normalize(hist_s, hist_s)\n",
    "    cv2.normalize(hist_v, hist_v)\n",
    "    \n",
    "    return np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274cc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "def load_and_extract_features(dataset_path):\n",
    "    data_features = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder_name in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"Processing class: {folder_name}\")\n",
    "            \n",
    "            for filename in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.resize(img, (256, 256))\n",
    "                \n",
    "                # Extract fitur gabungan\n",
    "                feat_glcm = extract_glcm_features(img)\n",
    "                feat_lbp = extract_lbp_features(img)\n",
    "                feat_hsv = extract_hsv_features(img)\n",
    "                \n",
    "                global_feature = np.concatenate([feat_glcm, feat_lbp, feat_hsv])\n",
    "                \n",
    "                data_features.append(global_feature)\n",
    "                labels.append(folder_name)\n",
    "                \n",
    "    return np.array(data_features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b8bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: H1\n",
      "Processing class: H2\n",
      "Processing class: H3\n",
      "Processing class: H5\n",
      "Processing class: H6\n",
      "\n",
      "Jumlah Data: 9114\n",
      "Dimensi Fitur: 40\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = 'dataset/' \n",
    "\n",
    "if os.path.exists(dataset_folder):\n",
    "    X, y = load_and_extract_features(dataset_folder)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    print(f\"\\nJumlah Data: {len(X)}\")\n",
    "    print(f\"Dimensi Fitur: {X.shape[1]}\") \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Path dataset tidak ditemukan. Harap ubah variabel 'dataset_folder'.\")\n",
    "    print(\"Pastikan struktur folder adalah: root/Kelas_Jamur/image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8f20f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training shape: (7291, 40)\n",
      "Resampled training shape: (17600, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original training shape: {X_train.shape}\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Resampled training shape: {X_train_resampled.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809e907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1. RANDOM FOREST ===\n",
      "Akurasi: 90.07%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.87      0.98      0.92       884\n",
      "          H2       0.92      0.79      0.85       486\n",
      "          H3       0.93      0.72      0.81       155\n",
      "          H5       0.96      0.93      0.94       157\n",
      "          H6       0.96      0.97      0.97       141\n",
      "\n",
      "    accuracy                           0.90      1823\n",
      "   macro avg       0.93      0.88      0.90      1823\n",
      "weighted avg       0.90      0.90      0.90      1823\n",
      "\n",
      "\n",
      "=== 2. SUPPORT VECTOR MACHINE (SVM) ===\n",
      "Akurasi SVM: 69.61%\n",
      "Classification Report SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.69      0.94      0.79       884\n",
      "          H2       0.61      0.31      0.41       486\n",
      "          H3       0.70      0.46      0.55       155\n",
      "          H5       0.78      0.66      0.72       157\n",
      "          H6       0.87      0.78      0.82       141\n",
      "\n",
      "    accuracy                           0.70      1823\n",
      "   macro avg       0.73      0.63      0.66      1823\n",
      "weighted avg       0.69      0.70      0.67      1823\n",
      "\n",
      "\n",
      "=== 3. K-NEAREST NEIGHBORS (KNN) ===\n",
      "Akurasi KNN: 88.48%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.94      0.87      0.90       884\n",
      "          H2       0.83      0.86      0.85       486\n",
      "          H3       0.71      0.88      0.79       155\n",
      "          H5       0.93      0.97      0.95       157\n",
      "          H6       0.94      0.99      0.96       141\n",
      "\n",
      "    accuracy                           0.88      1823\n",
      "   macro avg       0.87      0.91      0.89      1823\n",
      "weighted avg       0.89      0.88      0.89      1823\n",
      "\n",
      "\n",
      "=== 4. XGBOOST ===\n",
      "Akurasi XGBoost: 91.44%\n",
      "Classification Report XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.90      0.96      0.93       884\n",
      "          H2       0.89      0.85      0.87       486\n",
      "          H3       0.95      0.80      0.87       155\n",
      "          H5       0.96      0.93      0.94       157\n",
      "          H6       0.97      0.98      0.98       141\n",
      "\n",
      "    accuracy                           0.91      1823\n",
      "   macro avg       0.94      0.90      0.92      1823\n",
      "weighted avg       0.91      0.91      0.91      1823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== 1. RANDOM FOREST ===\")\n",
    "print(f\"Akurasi: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n=== 2. SUPPORT VECTOR MACHINE (SVM) ===\")\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) \n",
    "svm_model.fit(scaler.transform(X_train), y_train) # Must use scaled data\n",
    "\n",
    "y_pred_svm = svm_model.predict(scaler.transform(X_test))\n",
    "\n",
    "print(f\"Akurasi SVM: {accuracy_score(y_test, y_pred_svm) * 100:.2f}%\")\n",
    "print(\"Classification Report SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n=== 3. K-NEAREST NEIGHBORS (KNN) ===\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Akurasi KNN: {accuracy_score(y_test, y_pred_knn) * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n=== 4. XGBOOST ===\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob', \n",
    "    random_state=42,\n",
    "    num_class=5, # 5 classes\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train) \n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(f\"Akurasi XGBoost: {accuracy_score(y_test, y_pred_xgb) * 100:.2f}%\")\n",
    "print(\"Classification Report XGBoost:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d0c0407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Saving Models... ===\n",
      "Done! Models saved.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print(\"\\n=== Saving Models... ===\")\n",
    "joblib.dump(rf_model, 'rf_defungi.joblib')\n",
    "joblib.dump(svm_model, 'svm_defungi.joblib')\n",
    "joblib.dump(knn_model, 'knn_defungi.joblib')\n",
    "joblib.dump(xgb_model, 'xgb_defungi.joblib')\n",
    "joblib.dump(scaler, 'scaler_defungi.joblib') # Don't forget this!\n",
    "\n",
    "print(\"Done! Models saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comvis-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
