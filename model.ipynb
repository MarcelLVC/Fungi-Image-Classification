{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db363bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb # pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4098fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    # Ubah ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Hitung GLCM (jarak 1 pixel, sudut 0, 45, 90, 135 derajat)\n",
    "    # levels=256 karena citra 8-bit standard\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    features = []\n",
    "    # Properti yang ingin diambil\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    \n",
    "    for prop in props:\n",
    "        # Karena kita punya 4 sudut, kita ambil rata-ratanya agar fitur invarian terhadap rotasi\n",
    "        val = graycoprops(glcm, prop).mean()\n",
    "        features.append(val)\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0365c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Parameter LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    \n",
    "    # Hitung LBP (method 'uniform' bagus untuk rotasi invarian)\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Hitung histogram dari hasil LBP\n",
    "    # n_points + 2 adalah jumlah bin untuk method 'uniform'\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    \n",
    "    # Normalisasi histogram agar tidak terpengaruh ukuran gambar\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274cc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "def load_and_extract_features(dataset_path):\n",
    "    data_features = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder_name in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"Processing class: {folder_name}\")\n",
    "            \n",
    "            for filename in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resize gambar untuk mempercepat komputasi (opsional, tapi disarankan)\n",
    "                img = cv2.resize(img, (256, 256))\n",
    "                \n",
    "                # --- EKSTRAKSI FITUR GABUNGAN ---\n",
    "                feat_glcm = extract_glcm_features(img)\n",
    "                feat_lbp = extract_lbp_features(img)\n",
    "                feat_hsv = extract_hsv_features(img)\n",
    "                \n",
    "                # Gabungkan semua fitur menjadi satu vector panjang\n",
    "                global_feature = np.concatenate([feat_glcm, feat_lbp, feat_hsv])\n",
    "                \n",
    "                data_features.append(global_feature)\n",
    "                labels.append(folder_name)\n",
    "                \n",
    "    return np.array(data_features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a9815fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hsv_features(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Hitung histogram untuk setiap channel (Hue, Saturation, Value)\n",
    "    # bins=8 per channel agar fitur tidak terlalu banyak (total 24 fitur)\n",
    "    bins = 8\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [bins], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [bins], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [bins], [0, 256])\n",
    "    \n",
    "    # Normalisasi\n",
    "    cv2.normalize(hist_h, hist_h)\n",
    "    cv2.normalize(hist_s, hist_s)\n",
    "    cv2.normalize(hist_v, hist_v)\n",
    "    \n",
    "    # Gabungkan menjadi satu array datar\n",
    "    return np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: H1\n",
      "Processing class: H2\n",
      "Processing class: H3\n",
      "Processing class: H5\n",
      "Processing class: H6\n",
      "\n",
      "Jumlah Data: 9114\n",
      "Dimensi Fitur: 40\n",
      "\n",
      "Sedang melatih model Random Forest...\n",
      "\n",
      "=== HASIL EVALUASI ===\n",
      "Akurasi: 89.96%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.88      0.97      0.92       884\n",
      "          H2       0.91      0.80      0.85       486\n",
      "          H3       0.89      0.72      0.80       155\n",
      "          H5       0.96      0.92      0.94       157\n",
      "          H6       0.96      0.96      0.96       141\n",
      "\n",
      "    accuracy                           0.90      1823\n",
      "   macro avg       0.92      0.88      0.90      1823\n",
      "weighted avg       0.90      0.90      0.90      1823\n",
      "\n",
      "\n",
      "=== 2. SUPPORT VECTOR MACHINE (SVM) ===\n",
      "Sedang melatih model SVM...\n",
      "Akurasi SVM: 65.77%\n",
      "Classification Report SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.66      0.94      0.78       884\n",
      "          H2       0.53      0.27      0.36       486\n",
      "          H3       0.62      0.10      0.18       155\n",
      "          H5       0.73      0.68      0.70       157\n",
      "          H6       0.80      0.81      0.80       141\n",
      "\n",
      "    accuracy                           0.66      1823\n",
      "   macro avg       0.67      0.56      0.56      1823\n",
      "weighted avg       0.64      0.66      0.61      1823\n",
      "\n",
      "\n",
      "=== 3. K-NEAREST NEIGHBORS (KNN) ===\n",
      "Sedang melatih model KNN...\n",
      "Akurasi KNN: 72.79%\n",
      "Classification Report KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.76      0.89      0.82       884\n",
      "          H2       0.68      0.55      0.61       486\n",
      "          H3       0.67      0.51      0.58       155\n",
      "          H5       0.63      0.69      0.66       157\n",
      "          H6       0.78      0.57      0.66       141\n",
      "\n",
      "    accuracy                           0.73      1823\n",
      "   macro avg       0.70      0.64      0.67      1823\n",
      "weighted avg       0.72      0.73      0.72      1823\n",
      "\n",
      "\n",
      "=== 4. XGBOOST ===\n",
      "Sedang melatih model XGBoost...\n",
      "Akurasi XGBoost: 91.44%\n",
      "Classification Report XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.90      0.96      0.93       884\n",
      "          H2       0.89      0.85      0.87       486\n",
      "          H3       0.95      0.80      0.87       155\n",
      "          H5       0.96      0.93      0.94       157\n",
      "          H6       0.97      0.98      0.98       141\n",
      "\n",
      "    accuracy                           0.91      1823\n",
      "   macro avg       0.94      0.90      0.92      1823\n",
      "weighted avg       0.91      0.91      0.91      1823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ex\n",
    "dataset_folder = 'dataset/' \n",
    "\n",
    "if os.path.exists(dataset_folder):\n",
    "    X, y = load_and_extract_features(dataset_folder)\n",
    "    \n",
    "    # Encoding label string (misal: 'Candida') menjadi angka\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    print(f\"\\nJumlah Data: {len(X)}\")\n",
    "    print(f\"Dimensi Fitur: {X.shape[1]}\") # Cek berapa total fitur yang didapat\n",
    "    \n",
    "    # Split Data 80% Train, 20% Test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Random Forest\n",
    "    print(\"\\nSedang melatih model Random Forest...\")\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediksi\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluasi\n",
    "    print(\"\\n=== HASIL EVALUASI ===\")\n",
    "    print(f\"Akurasi: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    print(\"\\n=== 2. SUPPORT VECTOR MACHINE (SVM) ===\")\n",
    "    print(\"Sedang melatih model SVM...\")\n",
    "    # kernel='linear' is often best for HOG features. \n",
    "    # If accuracy is low, try kernel='rbf'\n",
    "    svm_model = SVC(kernel='linear', C=1.0, random_state=42) \n",
    "    svm_model.fit(X_train, y_train) # Must use Scaled data\n",
    "\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "    print(f\"Akurasi SVM: {accuracy_score(y_test, y_pred_svm) * 100:.2f}%\")\n",
    "    print(\"Classification Report SVM:\")\n",
    "    print(classification_report(y_test, y_pred_svm, target_names=le.classes_))\n",
    "\n",
    "\n",
    "    print(\"\\n=== 3. K-NEAREST NEIGHBORS (KNN) ===\")\n",
    "    print(\"Sedang melatih model KNN...\")\n",
    "    # n_neighbors=5 is standard. You can tune this (e.g., 3, 5, 7, 9)\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train) # Must use Scaled data\n",
    "\n",
    "    y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "    print(f\"Akurasi KNN: {accuracy_score(y_test, y_pred_knn) * 100:.2f}%\")\n",
    "    print(\"Classification Report KNN:\")\n",
    "    print(classification_report(y_test, y_pred_knn, target_names=le.classes_))\n",
    "\n",
    "    print(\"\\n=== 4. XGBOOST ===\")\n",
    "    print(\"Sedang melatih model XGBoost...\")\n",
    "    # XGBoost requires labels to be integers (0, 1, 2...), which LabelEncoder provides\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob', \n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train) # XGBoost handles unscaled data well\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "    print(f\"Akurasi XGBoost: {accuracy_score(y_test, y_pred_xgb) * 100:.2f}%\")\n",
    "    print(\"Classification Report XGBoost:\")\n",
    "    print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
    "    \n",
    "else:\n",
    "    print(\"Path dataset tidak ditemukan. Harap ubah variabel 'dataset_folder'.\")\n",
    "    print(\"Pastikan struktur folder adalah: root/Kelas_Jamur/image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809e907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# model_name = \"rfmodel_n100.joblib\"\n",
    "\n",
    "# joblib.dump(rf_model, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comvis-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
